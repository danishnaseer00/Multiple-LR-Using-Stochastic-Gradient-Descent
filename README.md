# ğŸ“Š Multiple Linear Regression from Scratch  
### Using Normal Equation & Stochastic Gradient Descent (SGD)

This project demonstrates how to implement **Multiple Linear Regression** from scratch using both the **Normal Equation** and **Stochastic Gradient Descent (SGD)**, without relying on high-level machine learning libraries like scikit-learn for the core algorithm.

---

## ğŸ“ Project Structure

.
â”œâ”€â”€ Multiple_Linear_regression_From_Scratch_Using_Normal_Equation_&_Stochastic_Gradient_Descent.ipynb
â””â”€â”€ README.md

---

## ğŸš€ Features

- âœ… Implementation of **Multiple Linear Regression** without `sklearn`
- âœ… Support for **Normal Equation Method**
- âœ… Support for **Stochastic Gradient Descent (SGD)**
- âœ… Uses **NumPy** and **Matplotlib** for computation and visualization
- âœ… Clear step-by-step markdown explanations

---

## ğŸ› ï¸ Libraries Used

- `numpy` â€“ for numerical operations  
- `matplotlib` â€“ for plotting graphs  
- `random` â€“ for stochastic behavior in SGD  
- `sklearn` (optional) â€“ only used for verification/comparison (not core implementation)

---

## â–¶ï¸ Running the Notebook

1. Clone this repository:
   ```bash
   git clone https://github.com/your-username/your-repo-name.git
Navigate to the project folder: 

cd your-repo-name
Launch the notebook:


jupyter notebook
Open the .ipynb file and run all cells.

âœï¸ Author
Danish
Feel free to connect or fork this notebook for your own experimentation!
