# 📊 Multiple Linear Regression from Scratch  
### Using Normal Equation & Stochastic Gradient Descent (SGD)

This project demonstrates how to implement **Multiple Linear Regression** from scratch using both the **Normal Equation** and **Stochastic Gradient Descent (SGD)**, without relying on high-level machine learning libraries like scikit-learn for the core algorithm.

---

## 📁 Project Structure

.
├── Multiple_Linear_regression_From_Scratch_Using_Normal_Equation_&_Stochastic_Gradient_Descent.ipynb
└── README.md

---

## 🚀 Features

- ✅ Implementation of **Multiple Linear Regression** without `sklearn`
- ✅ Support for **Normal Equation Method**
- ✅ Support for **Stochastic Gradient Descent (SGD)**
- ✅ Uses **NumPy** and **Matplotlib** for computation and visualization
- ✅ Clear step-by-step markdown explanations

---

## 🛠️ Libraries Used

- `numpy` – for numerical operations  
- `matplotlib` – for plotting graphs  
- `random` – for stochastic behavior in SGD  
- `sklearn` (optional) – only used for verification/comparison (not core implementation)

---

## ▶️ Running the Notebook

1. Clone this repository:
   ```bash
   git clone https://github.com/your-username/your-repo-name.git
Navigate to the project folder: 

cd your-repo-name
Launch the notebook:


jupyter notebook
Open the .ipynb file and run all cells.

✍️ Author
Danish
Feel free to connect or fork this notebook for your own experimentation!
